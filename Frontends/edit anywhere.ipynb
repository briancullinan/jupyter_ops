{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# edit anywhere\n",
    "\n",
    "Purpose: change the web however you want, save and restore it from github, treat the web like one giant web of gists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## introduction\n",
    "\n",
    "First attempt at this app was using megamind.bot app, the editor takes an input URL, and a filename.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " It loads a website from crawled data from Selenium/data collection.ipynb. It then sent these parameters to the client app for displaying in the same frame.\n",
    "\n",
    "The new implementation should act more like a marketing website. Enter a URL in a box in the middle like Google, use the controls that appear on the copied page content. Use different methods to get the page content such as Selenium crawler or simple phantom browser.\n",
    "\n",
    "After the content is crawled, make any changes that save to a single Gist for the entire domain. Load the gist from domain when the page is loaded (plugin phase 2).\n",
    "\n",
    "TODO:\n",
    "\n",
    "Fix SPA/PWA apps and canvas copies.\n",
    "\n",
    "Move page processing to generalized Selenium, convert scripts.\n",
    "\n",
    "TODO: Use print to PDF in chrome ignoring print styles from Developer mode, better Selenium crawler.\n",
    "\n",
    "TODO: Make a tool for the page manipulation, this is a common theme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "// readme.md? placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gist\n",
    "\n",
    "Read and write files from gist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### read gist files\n",
    "\n",
    "read gist files?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var Octokit = require('@octokit/rest');\n",
    "\n",
    "// commit changes to github\n",
    "function getGist(gist) {\n",
    "    if(!gist) return {}\n",
    "    const github = new Octokit({\n",
    "        host: 'api.github.com'\n",
    "    });\n",
    "    /*\n",
    "    github.authenticate({\n",
    "        type: 'basic',\n",
    "        username: process.env.USERNAME,\n",
    "        password: process.env.PASSWORD\n",
    "    });\n",
    "    */\n",
    "\n",
    "    //return github.gists.get({gist_id: gist})\n",
    "    return github.gists.get({gist_id: gist})\n",
    "        .then(r => r.data)\n",
    "        .catch(e => console.log(e))\n",
    "}\n",
    "\n",
    "module.exports = getGist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### test gist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var importer = require('../Core');\n",
    "var getGist = importer.import('read gist files');\n",
    "\n",
    "if(typeof $$ !== 'undefined') {\n",
    "    $$.async();\n",
    "    getGist('a572d0830ae72b962e12a57adaec7c52')\n",
    "        .then(r => $$.sendResult(r))\n",
    "        .catch(e => $$.sendError(e))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### write gist files\n",
    "\n",
    "write gist files?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var Octokit = require('@octokit/rest');\n",
    "\n",
    "// commit changes to github\n",
    "function updateGist(gist, files) {\n",
    "    if(!gist) return {}\n",
    "    const github = new Octokit({\n",
    "        host: 'api.github.com'\n",
    "    });\n",
    "    /*\n",
    "    github.authenticate({\n",
    "        type: 'basic',\n",
    "        username: process.env.USERNAME,\n",
    "        password: process.env.PASSWORD\n",
    "    });\n",
    "    */\n",
    "\n",
    "    //return github.gists.get({gist_id: gist})\n",
    "    return github.gists.update({\n",
    "        gist_id,\n",
    "        files\n",
    "    })\n",
    "        .then(r => r.data)\n",
    "        .catch(e => console.log(e))\n",
    "}\n",
    "\n",
    "module.exports = updateGist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save git\n",
    "\n",
    "This should be awkward. Submit the original file to the gist if it does not exist, then submit the changes to the HTML. Finally, parse out the HTML changes and reassociate classes/div.row-* sections back in to the spreadsheet for permanent storage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the code\n",
    "\n",
    "save git?\n",
    "\n",
    "git save?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var importer = require('../Core')\n",
    "var updateGist = importer.import('write gist files')\n",
    "\n",
    "function gitSave(url, data, gist) {\n",
    "    if(!gist) return {}\n",
    "    if(typeof url == 'string') {\n",
    "        url = new URL(url);\n",
    "    }\n",
    "    //console.log(url)\n",
    "    var host = url.hostname.replace(/[^a-z0-9_-]/ig, '_')\n",
    "    var file = url.pathname.replace(/[^a-z0-9_-]/ig, '_')\n",
    "    \n",
    "    // check if the file exists\n",
    "    const saved = (await getGist(gist)).files\n",
    "    if(typeof saved[file] === 'undefined') {\n",
    "        var files = await loadScraped(url)\n",
    "        var changes = {}\n",
    "        changes[file] = {content: files[file]}\n",
    "        if(files[file]) {\n",
    "            await updateGist(gist, files)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // add changes to gist\n",
    "    var changes = {}\n",
    "    changes[file] = {content: data}\n",
    "    await updateGist(gist, files)\n",
    "    \n",
    "    // diff the HTML for changes\n",
    "    \n",
    "    \n",
    "    // save the changes to spreadsheet\n",
    "    \n",
    "}\n",
    "\n",
    "module.exports = gitSave\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ckeditor client\n",
    "\n",
    "Use CKEditor and some scripts to apply some ACLs to the page and output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply ACL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the code\n",
    "apply acl to html?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var importer = require('../Core')\n",
    "var {selectDom} = importer.import('select tree')\n",
    "// scan using an acl list, similar to easylist?\n",
    "// TODO: accept formats:\n",
    "//    {\"selector\": \"selector\"}\n",
    "//    {\"glob-url@selector\": \"glob-template-path@selector\"}\n",
    "//    {\"selector\": \"html-file@selector\"}\n",
    "//    {\"selector\": \"html-file@xpath\"} ?\n",
    "//    {\"glob-file\": {\"glob-url\"...} || [\"selector\"]}\n",
    "const paths = JSON.parse('[]');\n",
    "\n",
    "function applyAcl(acl, doc) {\n",
    "    if(typeof doc === 'string') {\n",
    "        doc = selectDom('*', doc)\n",
    "    }\n",
    "    if(typeof acl === 'string') {\n",
    "        acl = [acl]\n",
    "    }\n",
    "    var body = selectDom('//body', doc)\n",
    "    if(body) {\n",
    "        // add content editable to -acl list elements\n",
    "        acl.forEach(i => {\n",
    "            var els = selectDom([i], body)\n",
    "            els.forEach(el => {\n",
    "                el.setAttribute('contenteditable', 'contenteditable')\n",
    "            })\n",
    "        })\n",
    "        return doc\n",
    "    } else {\n",
    "        throw Error(`Not found ${url}`)\n",
    "    }\n",
    "}\n",
    "\n",
    "module.exports = applyAcl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load ckeditor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the code\n",
    "\n",
    "load ckeditor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var {URL} = require('url')\n",
    "var importer = require('../Core')\n",
    "var loadScraped = importer.import('get scraped page')\n",
    "var getGist = importer.import('read gist files')\n",
    "var {selectDom} = importer.import('select tree')\n",
    "var applyAcl = importer.import('apply acl to html')\n",
    "\n",
    "// git \n",
    "async function gitEditor(url, gist, xpath) {\n",
    "    // TODO: use a Github repo as the input\n",
    "    if(typeof url == 'string') {\n",
    "        url = new URL(url);\n",
    "    }\n",
    "    var file = url.pathname.replace(/[^a-z0-9_-]/ig, '_')\n",
    "    var host = url.hostname.replace(/[^a-z0-9_-]/ig, '_')\n",
    "    if(!file) file = 'index'\n",
    "\n",
    "    var files = await loadScraped(url)\n",
    "    if(typeof files[ host + '-acl.json' ] === 'undefined') {\n",
    "        var saved = (await getGist(gist)).files\n",
    "        if(saved && saved[host + '-acl.json']) {\n",
    "            files[host + '-acl.json'] = JSON.parse(saved[host + '-acl.json'].content || '[]')\n",
    "        }\n",
    "    }\n",
    "    var doc = applyAcl((files[host + '-acl.json'] || []), files[file])\n",
    "    if(xpath) {\n",
    "        console.log(decodeURIComponent(xpath))\n",
    "        return selectDom([decodeURIComponent(xpath)], doc).map(el => el.outerHTML).join('')\n",
    "    }\n",
    "    return doc.outerHTML\n",
    "}\n",
    "\n",
    "module.exports = gitEditor\n",
    "\n",
    "if(typeof $$ !== 'undefined') {\n",
    "    $$.async();\n",
    "    gitEditor('https://www.google.com')\n",
    "        .then(r => $$.mime({'text/html': r}))\n",
    "        .catch(e => $$.sendError(e))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restrain CSS\n",
    "\n",
    "Replace all CSS rules with a container ID to restain it's affects on the page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the code\n",
    "\n",
    "restrain css? \n",
    "\n",
    "scope css?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var css = require('css');\n",
    "\n",
    "function prefixRule(r, str, prefix) {\n",
    "    if(typeof r.rules !== 'undefined') {\n",
    "        r.rules.forEach(r2 => prefixRule(r2, str, prefix))\n",
    "    }\n",
    "    if(typeof r.selectors === 'undefined') {\n",
    "        return;\n",
    "    }\n",
    "    r.selectors.forEach((s, i) => {\n",
    "        if(s.includes('body')) {\n",
    "            r.selectors[i] = s.replace(/\\s*body\\s*/ig, prefix);\n",
    "        } else {\n",
    "            r.selectors[i] = prefix + ' ' + s;\n",
    "        }\n",
    "    });\n",
    "}\n",
    "\n",
    "function prefixCssRules(str, prefix) {\n",
    "    try {\n",
    "        const ast = css.parse(str);\n",
    "        // TODO: add a check for media queries\n",
    "        ast.stylesheet.rules.forEach(r => prefixRule(r, str, prefix))\n",
    "        return css.stringify(ast);\n",
    "    } catch (e) {\n",
    "        console.log(e)\n",
    "        return str\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "module.exports = prefixCssRules;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TODO: express crawl middleware\n",
    "\n",
    "Serve every static address from a cache crawl json file.\n",
    "\n",
    "TODO: move this to data collection tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read crawl files\n",
    "\n",
    "Load matching files from a crawled cache json file. See Selenium/data collection.ipynb for more information on crawl cache json.\n",
    "\n",
    "TODO: move this to data collection.ipynb tools and use with \"convert spreadsheet\"/AMP emulator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the code \n",
    "\n",
    "read crawl files?\n",
    "\n",
    "get scraped page?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var path = require('path')\n",
    "var fs = require('fs')\n",
    "var {URL} = require('url')\n",
    "var uuid = require('uuid/v1')\n",
    "var importer = require('../Core')\n",
    "var {glob} = importer.import('glob files')\n",
    "var {minimatch} = importer.import('minimatch')\n",
    "var {selectDom} = importer.import('select tree')\n",
    "var prefixCssRules = importer.import('scope css')\n",
    "var {findCache} = importer.import('domain crawler tools')\n",
    "\n",
    "var PROFILE_PATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE || '';\n",
    "var project = path.join(PROFILE_PATH, 'Collections/crawls');\n",
    "\n",
    "function matchPage(match, search, hostname) {\n",
    "    return search.includes(match)\n",
    "        || minimatch(search, match)\n",
    "        || (!match || match === 'index')\n",
    "        && search.match(/https?:\\/\\/[^\\/]*\\/?$/ig)\n",
    "        && search.includes(hostname)\n",
    "}\n",
    "\n",
    "function loadScraped(url) {\n",
    "    if(typeof url == 'string') {\n",
    "        url = new URL(url);\n",
    "    }\n",
    "    //console.log(url)\n",
    "    var host = url.hostname.replace(/[^a-z0-9_-]/ig, '_')\n",
    "    var file = url.pathname\n",
    "    if(!file) file = 'index'\n",
    "    \n",
    "    // lookup on filesystem\n",
    "    var cache = findCache(host)\n",
    "    if(!cache[0]) {\n",
    "        return\n",
    "    }\n",
    "    const crawl = JSON.parse(fs.readFileSync(cache[0]).toString());\n",
    "    const entry = crawl.filter(r => matchPage(file, r.url, host))[0];\n",
    "    const result = {}\n",
    "    //console.log(entry)\n",
    "    // parse out styles and images and package it up in to one nice page\n",
    "    if(entry) {\n",
    "        var doc = selectDom('*', entry.html)\n",
    "        var styles = selectDom(['//link[@rel = \"stylesheet\"]|//style'], doc)\n",
    "        var css = ''\n",
    "        styles.forEach(s => {\n",
    "            var src = s.getAttribute('src') || s.getAttribute('href')\n",
    "            s.remove()\n",
    "            if(!src) {\n",
    "                css += s.innerHTML\n",
    "                return\n",
    "            }\n",
    "            src = new URL(src, url).href\n",
    "            var rules = crawl.filter(r => r.url === src)[0]\n",
    "            if(rules) {\n",
    "                css += rules.content\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        var scripts = selectDom(['//script|//iframe'], doc)\n",
    "        scripts.forEach(s => s.remove())\n",
    "        \n",
    "        var images = selectDom(['//img'], doc)\n",
    "        images.forEach(i => {\n",
    "            var src = i.getAttribute('src')\n",
    "            src = new URL(src, url).href\n",
    "            var images = crawl.filter(r => r.url === src)[0]\n",
    "            if(images && images.content.includes('data:')) {\n",
    "                i.setAttribute('src', images.content)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        var links = selectDom(['//a'], doc)\n",
    "        links.forEach(l => {\n",
    "            var src = l.getAttribute('href')\n",
    "            src = new URL(src, url).href\n",
    "            l.setAttribute('href', '/?url=' + src)\n",
    "        })\n",
    "        \n",
    "        // TODO: load images as data URIs and lower quality\n",
    "        css = prefixCssRules(css, '#' + host)\n",
    "            .replace(/url\\s*\\(['\"]*([^\\)]*?)['\"]*\\)/ig, ($0, $1) => {\n",
    "                var src = new URL($1, url).href\n",
    "                var images = crawl.filter(r => r.url === src)[0]\n",
    "                if(images && images.content.includes('data:')) {\n",
    "                    return `url(${images.content})`\n",
    "                }\n",
    "                return $0\n",
    "            })\n",
    "            .replace(/href=\"([^\\\"]*)\"/ig, ($0, $1) => {\n",
    "                var src = new URL($1, url).href\n",
    "                return $0.replace($1, '/?url=' + src)\n",
    "            })\n",
    "\n",
    "        // inject the editor into copied page\n",
    "        var body = selectDom('//body', doc)\n",
    "        var classes = body.getAttribute('class')\n",
    "        result[file.replace(/[^a-z0-9_-]/ig, '_')] = `\n",
    "<html><head><style>\n",
    "body, html {\n",
    "    margin: 0;\n",
    "    padding: 0;\n",
    "}\n",
    "</style><style>${css}</style>\n",
    "</head><body><div id=\"${host}\" class=\"${classes}\">${body.innerHTML}</div>\n",
    "<script>\n",
    "${importer.interpret('ckeditor configuration').code}\n",
    "</script>\n",
    "</body></html>`\n",
    "    }\n",
    "    return result\n",
    "}\n",
    "\n",
    "module.exports = loadScraped\n",
    "\n",
    "//var importer = require('../Core')\n",
    "//var loadScraped = importer.import('read crawl files')\n",
    "\n",
    "if(typeof $$ != 'undefined') {\n",
    "    var scraped = loadScraped('https://google.com')\n",
    "    $$.html(scraped)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ckeditor configuration?\n",
    "\n",
    "Source of XHR code:\n",
    "\n",
    "https://gomakethings.com/ajax-and-apis-with-vanilla-javascript/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveEdits(data) {\n",
    "    return new Promise((resolve, reject) => {\n",
    "        var xhr = new XMLHttpRequest()\n",
    "        xhr.setHeader('X-Referrer', window.location)\n",
    "        xhr.onload = function () {\n",
    "            if (xhr.status >= 200 && xhr.status < 300) {\n",
    "                resolve(xhr)\n",
    "            } else {\n",
    "                reject(new Error('The request failed!'))\n",
    "            }\n",
    "        }\n",
    "        xhr.open('GET', window.location.href.replace('gitEditorHandler', 'gitSaveHandler')\n",
    "                 + '?referrer=' + window.location.href\n",
    "                 // TODO: use referer in receiving function for this\n",
    "                 + '&gist=' + window.location.search.match(/[\\?&]gist=([^&]*)/ig)[1]\n",
    "                 + '&url=' + window.location.search.match(/[\\?&]url=([^&]*)/ig)[1]\n",
    "        xhr.send(data)\n",
    "    })\n",
    "}\n",
    "\n",
    "var script = document.createElement('script')\n",
    "script.onload = function () {\n",
    "    var editors = document.querySelectorAll( '*[contenteditable]' )\n",
    "    editors.forEach(e => {\n",
    "        InlineEditor\n",
    "        .create( e,  plugins: [\n",
    "            Autosave,\n",
    "        ],\n",
    "\n",
    "        autosave: {\n",
    "            save( editor ) {\n",
    "                return saveEdits( editor.getData() );\n",
    "            }\n",
    "        } )\n",
    "        .catch( error => console.error( error ) )\n",
    "        \n",
    "    })\n",
    "}\n",
    "\n",
    "script.setAttribute('src', 'https://cdn.ckeditor.com/ckeditor5/16.0.0/inline/ckeditor.js')\n",
    "document.body.appendChild(script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test crawl cache loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "12.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
